{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\npd.set_option('display.max_column', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport shap\n\nimport scipy.stats\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom yellowbrick.cluster import KElbowVisualizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-01-12T18:43:04.407844Z","iopub.execute_input":"2023-01-12T18:43:04.408321Z","iopub.status.idle":"2023-01-12T18:43:10.282370Z","shell.execute_reply.started":"2023-01-12T18:43:04.408221Z","shell.execute_reply":"2023-01-12T18:43:10.280889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Customer Segmentation Analysis\n\nIn this project, I will be performing a customer segmentation of clients that are regular customers of a fictional product. This example is given as follows: Imagine that this fictitious company wants to launch a new product on the market, which group of customers is the most suitable to promote the product?\n\nThe results that I am looking foward are:\n\n- Segment the customers in distinct groups\n- Explore the characteristics of each group\n- Explore why the classification model assigned a customer to his group\n\nThe dataset that I will be using is generated by random variables with some expected characteristics that could be provided by a generic company","metadata":{}},{"cell_type":"code","source":"# Generate 1000 random rows for the dataframe\nrandom.seed(42)\ndata = []\nsex = [\"Female\",\"Male\"]\nfor i in range(1000):\n    data.append({\n        'sex': random.choice(sex),\n        'age': random.randint(18, 75),\n        'monthly_visits': random.randint(1, 45),\n        'total_purchase_amount': random.randint(40000, 365000),\n        'distinct_products' : random.randint(1,50),\n        'monthly_purchases_avg' : random.randint(12,30),\n        'avg_purchase_price': random.uniform(105.5,2500)\n    })\n\ndf = pd.DataFrame(data)\ndf.avg_purchase_price = df.avg_purchase_price.round(2)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:10.284118Z","iopub.execute_input":"2023-01-12T18:43:10.284645Z","iopub.status.idle":"2023-01-12T18:43:10.336896Z","shell.execute_reply.started":"2023-01-12T18:43:10.284616Z","shell.execute_reply":"2023-01-12T18:43:10.335202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains data from users, here are the featuers:\n\n- Age of the user\n- Sex of the user\n- How many visits in the last month\n- Total purchases\n- Distinct products bought\n- Quantity of produts bought last month\n- Average purchase price\n\nSince the data was randomized, there is no need to drop missing values","metadata":{}},{"cell_type":"markdown","source":"Let's have a look at the data's stats.","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:10.339610Z","iopub.execute_input":"2023-01-12T18:43:10.340014Z","iopub.status.idle":"2023-01-12T18:43:10.387420Z","shell.execute_reply.started":"2023-01-12T18:43:10.339984Z","shell.execute_reply":"2023-01-12T18:43:10.386442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(ncols=3, nrows = 2)\n\nsns.boxplot(y = df['age'], color= '#eea990', ax = axs[0,0])\nsns.boxplot(y = df['monthly_visits'], color= '#eea990', ax = axs[0,1])\nsns.boxplot(y = df['total_purchase_amount'], color= '#eea990', ax = axs[0,2])\nsns.boxplot(y = df['distinct_products'], color= '#eea990', ax = axs[1,0])\nsns.boxplot(y = df['monthly_purchases_avg'], color= '#eea990', ax = axs[1,1])\nsns.boxplot(y = df['avg_purchase_price'], color= '#eea990', ax = axs[1,2])\nfig.set_size_inches(20, 13)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:10.389580Z","iopub.execute_input":"2023-01-12T18:43:10.389965Z","iopub.status.idle":"2023-01-12T18:43:11.216811Z","shell.execute_reply.started":"2023-01-12T18:43:10.389938Z","shell.execute_reply":"2023-01-12T18:43:11.214984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize= (16, 8))\nsns.heatmap(df.corr(), annot = True, cmap= 'YlGnBu')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:11.218346Z","iopub.execute_input":"2023-01-12T18:43:11.218699Z","iopub.status.idle":"2023-01-12T18:43:11.686222Z","shell.execute_reply.started":"2023-01-12T18:43:11.218671Z","shell.execute_reply":"2023-01-12T18:43:11.684462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the data is randomized, it is expected a low correlation between the variables, and a very well distributed dataset","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Data treatment before modeling\n\n1)Encoding categorical variables\n\n2)Standard scaling all values\n\n3)PCA to three dimensions","metadata":{}},{"cell_type":"code","source":"df = pd.get_dummies(df)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:11.687976Z","iopub.execute_input":"2023-01-12T18:43:11.688324Z","iopub.status.idle":"2023-01-12T18:43:11.701844Z","shell.execute_reply.started":"2023-01-12T18:43:11.688298Z","shell.execute_reply":"2023-01-12T18:43:11.699611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:11.704060Z","iopub.execute_input":"2023-01-12T18:43:11.704478Z","iopub.status.idle":"2023-01-12T18:43:11.726190Z","shell.execute_reply.started":"2023-01-12T18:43:11.704449Z","shell.execute_reply":"2023-01-12T18:43:11.724020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All features are now numeric","metadata":{}},{"cell_type":"markdown","source":"Standardize features by removing the mean and scaling to unit variance.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nscaler.fit(df)\n\ndf_scaled = pd.DataFrame(scaler.transform(df), columns=df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:11.730620Z","iopub.execute_input":"2023-01-12T18:43:11.732609Z","iopub.status.idle":"2023-01-12T18:43:11.745336Z","shell.execute_reply.started":"2023-01-12T18:43:11.732539Z","shell.execute_reply":"2023-01-12T18:43:11.743758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scaled.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:11.747088Z","iopub.execute_input":"2023-01-12T18:43:11.747477Z","iopub.status.idle":"2023-01-12T18:43:11.762233Z","shell.execute_reply.started":"2023-01-12T18:43:11.747449Z","shell.execute_reply":"2023-01-12T18:43:11.761228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Principal component analysis (PCA).\n\nLinear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. ","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=3)\npca.fit(df_scaled)\ndf_PCA = pd.DataFrame(pca.transform(df_scaled), columns=([\"col1\",\"col2\", \"col3\"]))\ndf_PCA.describe()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:11.766733Z","iopub.execute_input":"2023-01-12T18:43:11.767733Z","iopub.status.idle":"2023-01-12T18:43:11.812359Z","shell.execute_reply.started":"2023-01-12T18:43:11.767688Z","shell.execute_reply":"2023-01-12T18:43:11.811086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualizing the date before modeling","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,8))\nax = fig.add_subplot(111, projection=\"3d\")\nax.scatter(df_PCA[\"col1\"],df_PCA[\"col2\"],df_PCA[\"col3\"], c=\"red\", marker=\"o\")\nax.set_title(\"Data visualization PCA\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:11.813911Z","iopub.execute_input":"2023-01-12T18:43:11.814322Z","iopub.status.idle":"2023-01-12T18:43:12.102041Z","shell.execute_reply.started":"2023-01-12T18:43:11.814286Z","shell.execute_reply":"2023-01-12T18:43:12.099828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Clustering","metadata":{}},{"cell_type":"markdown","source":"Utilizing a simple K-Means model for clustering\n\n1)Finding k amount of clusters required\n\n2)Adjusting dataset to model\n\n3)Visualize results","metadata":{}},{"cell_type":"code","source":"Elbow = KElbowVisualizer(KMeans(), k=10)\nElbow.fit(df_PCA)\nElbow.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:12.104343Z","iopub.execute_input":"2023-01-12T18:43:12.104865Z","iopub.status.idle":"2023-01-12T18:43:13.541164Z","shell.execute_reply.started":"2023-01-12T18:43:12.104819Z","shell.execute_reply":"2023-01-12T18:43:13.538859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By the elbow curve, it indicates that a good value for k is 6","metadata":{}},{"cell_type":"code","source":"AC = KMeans(n_clusters=6)\nyhat_AC = AC.fit_predict(df_PCA)\n\ndf_PCA[\"Clusters\"] = yhat_AC","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:13.542884Z","iopub.execute_input":"2023-01-12T18:43:13.543246Z","iopub.status.idle":"2023-01-12T18:43:13.685613Z","shell.execute_reply.started":"2023-01-12T18:43:13.543210Z","shell.execute_reply":"2023-01-12T18:43:13.684508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To examine the clusters formed let's have a look at the 3-D distribution of the clusters","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(10,8))\nax = plt.subplot(111, projection='3d', label=\"bla\")\nax.scatter(df_PCA[\"col1\"],df_PCA[\"col2\"],df_PCA[\"col3\"], s=40, c=df_PCA[\"Clusters\"], marker='o', cmap = \"Accent\")\nax.set_title(\"Visualization of Clusters\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:13.686790Z","iopub.execute_input":"2023-01-12T18:43:13.687384Z","iopub.status.idle":"2023-01-12T18:43:13.924575Z","shell.execute_reply.started":"2023-01-12T18:43:13.687354Z","shell.execute_reply":"2023-01-12T18:43:13.923286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = sns.countplot(x=df_PCA[\"Clusters\"], palette= \"Accent\")\nfig.set_title(\"Cluster Distribuition\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:13.926195Z","iopub.execute_input":"2023-01-12T18:43:13.926780Z","iopub.status.idle":"2023-01-12T18:43:14.117775Z","shell.execute_reply.started":"2023-01-12T18:43:13.926743Z","shell.execute_reply":"2023-01-12T18:43:14.116361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's have a look at the group distribution of clustring","metadata":{}},{"cell_type":"code","source":"df[\"Clusters\"] = df_PCA.loc[:,\"Clusters\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:14.119233Z","iopub.execute_input":"2023-01-12T18:43:14.119817Z","iopub.status.idle":"2023-01-12T18:43:14.127671Z","shell.execute_reply.started":"2023-01-12T18:43:14.119782Z","shell.execute_reply":"2023-01-12T18:43:14.125518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(ncols=3, nrows = 2)\n\nsns.boxplot(y = df['age'], x = df['Clusters'], color= '#eea990', ax = axs[0,0])\nsns.boxplot(y = df['monthly_visits'], x = df['Clusters'], color= '#eea990', ax = axs[0,1])\nsns.boxplot(y = df['total_purchase_amount'], x = df['Clusters'], color= '#eea990', ax = axs[0,2])\nsns.boxplot(y = df['distinct_products'], x = df['Clusters'], color= '#eea990', ax = axs[1,0])\nsns.boxplot(y = df['monthly_purchases_avg'], x =df['Clusters'], color= '#eea990', ax = axs[1,1])\nsns.boxplot(y = df['avg_purchase_price'], x = df['Clusters'], color= '#eea990', ax = axs[1,2])\nfig.set_size_inches(20, 13)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:14.129905Z","iopub.execute_input":"2023-01-12T18:43:14.130319Z","iopub.status.idle":"2023-01-12T18:43:15.608225Z","shell.execute_reply.started":"2023-01-12T18:43:14.130289Z","shell.execute_reply":"2023-01-12T18:43:15.607070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data = df, hue = \"Clusters\")","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:15.609518Z","iopub.execute_input":"2023-01-12T18:43:15.609847Z","iopub.status.idle":"2023-01-12T18:43:41.181266Z","shell.execute_reply.started":"2023-01-12T18:43:15.609820Z","shell.execute_reply":"2023-01-12T18:43:41.179607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The clusters seems to bee farly distribuited","metadata":{}},{"cell_type":"markdown","source":"This is a table contaning some agregated data of the clusters generated, we can already see some well positioned clustering","metadata":{}},{"cell_type":"code","source":"df.pivot_table(index = 'Clusters',aggfunc = (['min','max','mean'])).T","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:41.183160Z","iopub.execute_input":"2023-01-12T18:43:41.183568Z","iopub.status.idle":"2023-01-12T18:43:41.252457Z","shell.execute_reply.started":"2023-01-12T18:43:41.183539Z","shell.execute_reply":"2023-01-12T18:43:41.250570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Going back to our problem, which group of customers would be the most fitted for the new product that is beeing created, could be solved by the pivot table above, looking at the data we can see some patterns for our groups resulting in a target for the product.\n\nBut we can go even further, what if the product/market team wants to know how one group differ from another, in other words, what are the most important features that impact the classification for each cluster","metadata":{}},{"cell_type":"markdown","source":"## Classification","metadata":{}},{"cell_type":"markdown","source":"Utilizing a Random Forest with no pruning, to train a model based on K Means classification. By utilizing a Random Forest it is possible to apply a shap explainer and understand which variable had a bigger impact in the ouput of each cluster","metadata":{}},{"cell_type":"code","source":"df[\"Clusters\"] = df_PCA.loc[:,\"Clusters\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:41.254595Z","iopub.execute_input":"2023-01-12T18:43:41.255095Z","iopub.status.idle":"2023-01-12T18:43:41.262591Z","shell.execute_reply.started":"2023-01-12T18:43:41.255060Z","shell.execute_reply":"2023-01-12T18:43:41.260952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:41.263974Z","iopub.execute_input":"2023-01-12T18:43:41.264397Z","iopub.status.idle":"2023-01-12T18:43:41.277851Z","shell.execute_reply.started":"2023-01-12T18:43:41.264367Z","shell.execute_reply":"2023-01-12T18:43:41.276091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:41.280677Z","iopub.execute_input":"2023-01-12T18:43:41.281322Z","iopub.status.idle":"2023-01-12T18:43:41.291782Z","shell.execute_reply.started":"2023-01-12T18:43:41.281274Z","shell.execute_reply":"2023-01-12T18:43:41.289802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = RandomForestClassifier(criterion = 'entropy')\nclassifier.fit(X_train, y_train)\n\ny_pred = classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:41.294225Z","iopub.execute_input":"2023-01-12T18:43:41.295746Z","iopub.status.idle":"2023-01-12T18:43:41.549703Z","shell.execute_reply.started":"2023-01-12T18:43:41.295683Z","shell.execute_reply":"2023-01-12T18:43:41.548129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_matrix = confusion_matrix(y_test, y_pred)\nprint(c_matrix)\naccuracy_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:41.551374Z","iopub.execute_input":"2023-01-12T18:43:41.551959Z","iopub.status.idle":"2023-01-12T18:43:41.566226Z","shell.execute_reply.started":"2023-01-12T18:43:41.551922Z","shell.execute_reply":"2023-01-12T18:43:41.564156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the random forest classifier we got a R² of 0.875","metadata":{}},{"cell_type":"markdown","source":"Applying shap to see the impact of each feature on the classification model","metadata":{}},{"cell_type":"code","source":"explainer = shap.TreeExplainer(classifier)\nshap_values = explainer.shap_values(X)\nshap.summary_plot(shap_values, X_train,feature_names = df.iloc[:, :-1].columns)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T18:43:41.569673Z","iopub.execute_input":"2023-01-12T18:43:41.570169Z","iopub.status.idle":"2023-01-12T18:43:45.510633Z","shell.execute_reply.started":"2023-01-12T18:43:41.570132Z","shell.execute_reply":"2023-01-12T18:43:45.508980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With shap values we can see that for exemple, that Class 3 age have a bigger inpact than monthly_visits, with this logic we can analyse and create more impactfull insights over the classification","metadata":{}},{"cell_type":"markdown","source":"## Conclusion\n\nIn this project, I performed unsupervised clustering. I did use dimensionality reduction followed by Kmeans clustering. I came up with 6 clusters and further used them in a Random Forest Classifier to get a sense of metric score from the k Means, and then I Applyed Shap values to understand better how each feature inpact the segment of our clusters.","metadata":{}}]}
